+++
title = "Kubeflow"
+++

<!-- Hero section -->
{{< blocks/cover title="Kubeflow" image_anchor="center" height="full" color="primary" >}}
<div class="mx-auto">
	<p class="lead mt-5">The Machine Learning Toolkit for Kubernetes</p>
	<a class="btn btn-lg btn-primary mr-3 mb-4" href="/docs/started/getting-started/">
		Get Started <i class="fas fa-arrow-alt-circle-right ml-2"></i>
	</a>
	<a class="btn btn-lg btn-secondary mr-3 mb-4" href="/docs/about/contributing/">
		Contribute <i class="fas fa-arrow-alt-circle-right ml-2"></i>
	</a>
	<div class="mx-auto mt-5">
			{{< blocks/link-down color="info" >}}
		</div>
</div>
{{< /blocks/cover >}}

{{< blocks/lead color="dark" >}}
<h2>What is Kubeflow?</h2>

<p>The Kubeflow project is dedicated to making deployments of machine learning
	 (ML) workflows on Kubernetes simple, portable and scalable. Our goal is not 
	 to recreate other services, but to provide a straightforward way to deploy 
	 best-of-breed open-source systems for ML to diverse infrastructures. 
	 Anywhere you are running Kubernetes, you should be able to run Kubeflow.</p>
{{% /blocks/lead %}}

{{< blocks/section color="main" >}}
<img src="logo-jupyter.svg" alt="Jupyter logo">

<h4>Notebooks</h4>

<p>A JupyterHub to create and manage interactive Jupyter notebooks. Project 
	Jupyter is a non-profit, open-source project to support interactive data 
	science and scientific computing across all programming languages.</p>
{{< /blocks/section >}}

{{< blocks/section color="main" >}}
<img src="logo-tensorflow.svg" alt="TensorFlow logo">

<h4>TensorFlow model training</h4>

<p>A TensorFlow training controller that can be configured to use either CPUs or
	GPUs and be dynamically adjusted to the size of a cluster with a single 
	setting. We also provide a TensorFlow job operator.</p>
{{< /blocks/section >}}

{{< blocks/section color="main" >}}
<object type="image/svg+xml" data="serving.svg"></object>

<h4>Model serving</h4>

<p>A TensorFlow Serving container to export trained TensorFlow models to 
	Kubernetes. We also integrate with Seldon Core, an open source platform for 
	deploying machine learning models on Kubernetes, and NVIDIA TensorRT Inference 
	Server for maximized GPU utilization when deploying ML/DL models at scale.</p>
{{< /blocks/section >}}

{{< blocks/section color="main" >}}
<object type="image/svg+xml" data="pipelines.svg"></object>

<h4>Pipelines</h4>

<p>A solution to deploy and manage end-to-end machine learning workflows, 
  providing rapid and reliable ML experimentation.</p>
{{< /blocks/section >}}

{{< blocks/section color="main" >}}
<object type="image/svg+xml" data="multi-framework.svg"></object>

<h4>Multi-framework</h4>

<p>Our development plans go beyond TensorFlow, and we are working hard to 
	include PyTorch, MXNet, Chainer, and more. We also integrate with Ambassador 
	for ingress and Pachyderm for managing your data science pipelines.</p>
{{< /blocks/section >}}

{{< blocks/section color="main" >}}
<img src="icn-people.svg" alt="People icon">

<h4>Community</h4>

<p>We are an open and welcoming community of software developers, data 
	scientists, and organizations that are working to make it easier to develop 
	and deploy scalable ML workflows across the industry. 
	<a href="/docs/about/contributing/">Start contributing.</p>
{{< /blocks/section >}}

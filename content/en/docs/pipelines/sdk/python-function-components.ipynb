{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Python function-based components\n",
    "> Building your own lightweight pipelines components using Python\n",
    "\n",
    "A Kubeflow Pipelines component is a self-contained set of code that performs one step in your\n",
    "ML workflow. A pipeline component is composed of:\n",
    "\n",
    "*   The component code, which implements the logic needed to perform a step in your ML workflow.\n",
    "*   A component specification, which defines the following:\n",
    "    \n",
    "    *   The component's metadata, its name and description.\n",
    "    *   The component's interface, the component's inputs and outputs.\n",
    "    *   The component's implementation, the Docker container image\n",
    "        to run, how to pass inputs to your component code, and how\n",
    "        to get the component's outputs.\n",
    "\n",
    "Python function-based components make it easier to iterate quickly by letting you build your\n",
    "component code as a Python function and generating the [component specification][component-spec] for you.\n",
    "This document describes how to build Python function-based components and use them in your pipeline.\n",
    "\n",
    "[component-spec]: https://www.kubeflow.org/docs/pipelines/reference/component-spec/\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "1. Run the following command to install the Kubeflow Pipelines SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install kfp --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Import the `kfp` and `kfp.components` packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp\n",
    "import kfp.components as comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create an instance of the [`kfp.Client` class][kfp-client].\n",
    "\n",
    "[kfp-client]: https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.client.html#kfp.Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run this command on a Jupyter notebook running on Kubeflow, you can\n",
    "# exclude the host parameter.\n",
    "# client = kfp.Client()\n",
    "client = kfp.Client(host='<your-kubeflow-pipelines-host-name>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about the Kubeflow Pipelines SDK, see the [SDK reference guide][sdk-ref].\n",
    "\n",
    "[sdk-ref]: https://kubeflow-pipelines.readthedocs.io/en/latest/index.html\n",
    "\n",
    "## Getting started with Python function-based components\n",
    "\n",
    "This section demonstrates how to get started building Python function-based components by walking\n",
    "through the process of creating a simple component.\n",
    "\n",
    "1.  Define your component's code as a [standalone python function](#standalone). In this example,\n",
    "    the function adds two floats and returns the sum of the two arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a: float, b: float) -> float:\n",
    "  '''Calculates sum of two arguments'''\n",
    "  return a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Use `kfp.components.create_component_from_func` to generate the component specification YAML and return a\n",
    "    factory function that you can use to create [`kfp.dsl.ContainerOp`][container-op] class instances for your pipeline.\n",
    "    The component specification YAML is a reusable and shareable definition of your component.\n",
    "\n",
    "[container-op]: https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#kfp.dsl.ContainerOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_op = comp.create_component_from_func(\n",
    "    add, output_component_file='add_component.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  Create and run your pipeline. [Learn more about creating and running pipelines][build-pipelines].\n",
    "\n",
    "[build-pipelines]: https://www.kubeflow.org/docs/pipelines/sdk/build-component/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "  name='Addition pipeline',\n",
    "  description='An example pipeline that performs addition calculations.'\n",
    ")\n",
    "def add_pipeline(\n",
    "  a='3',\n",
    "  b='7',\n",
    "):\n",
    "  # Passes a pipeline parameter and a constant value to the `add_op` factory\n",
    "  # function.\n",
    "  first_add_task = add_op(a, 4)\n",
    "  # Passes an output reference from `first_add_task` and a pipeline parameter\n",
    "  # to the `add_op` factory function. For operations with a single return\n",
    "  # value, the output reference can be accessed as `task.output` or\n",
    "  # `task.outputs['output_name']`.\n",
    "  second_add_task = add_op(add_task.output, b)\n",
    "\n",
    "# Specify argument values for your pipeline run.\n",
    "arguments = {'a': '7', 'b': '8'}\n",
    "\n",
    "# Create a pipeline run, using the client you initialized in a prior step.\n",
    "client.create_run_from_pipeline_func(add_pipeline, arguments=arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Python function-based components\n",
    "\n",
    "Use the following instructions to build a Python function-based component:\n",
    "\n",
    "<a name=\"standalone\"></a>\n",
    "\n",
    "1.  Define a stand-alone Python function. This function must meet the following requirements:\n",
    "\n",
    "    *   It should not use any code declared outside of the function definition.\n",
    "    *   Import statements must be added inside the function. [Learn more about using and installing\n",
    "        Python packages in your component](#packages).\n",
    "    *   Helper functions must be defined inside this function.\n",
    "    *   If the function accepts numeric values as parameters, the parameters must have type hints.\n",
    "        Supported types are `int`, `float`, and `bool`. Otherwise, parameters are passed as strings.\n",
    "    *   If your component returns multiple outputs, annotate your function with the\n",
    "        [`typing.NamedTuple`][named-tuple-hint] type hint and use the [`collections.namedtuple`][named-tuple]\n",
    "        function return your function's outputs as a new subclass of tuple.\n",
    "        \n",
    "        You can also return metadata and metrics from your function. \n",
    "        \n",
    "        *  Metadata helps you visualize pipeline results.\n",
    "           [Learn more about visualizing pipeline metadata][kfp-visualize].\n",
    "        *  Metrics help you compare pipeline runs.\n",
    "           [Learn more about using pipeline metrics][kfp-metrics].\n",
    "        \n",
    "[named-tuple-hint]: https://docs.python.org/3/library/typing.html#typing.NamedTuple\n",
    "[named-tuple]: https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "[kfp-visualize]: https://www.kubeflow.org/docs/pipelines/sdk/output-viewer/\n",
    "[kfp-metrics]: https://www.kubeflow.org/docs/pipelines/sdk/pipelines-metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "def multiple_return_values_example(a: float, b: float) -> NamedTuple(\n",
    "  'ExampleOutputs',\n",
    "  [\n",
    "    ('sum', float),\n",
    "    ('product', float),\n",
    "    ('mlpipeline_ui_metadata', 'UI_metadata'),\n",
    "    ('mlpipeline_metrics', 'Metrics')\n",
    "  ]):\n",
    "  \"\"\"Example function that demonstrates how to return multiple values.\"\"\"  \n",
    "  sum_value = a + b\n",
    "  product_value = a * b\n",
    "\n",
    "  # Export a sample tensorboard\n",
    "  metadata = {\n",
    "    'outputs' : [{\n",
    "      'type': 'tensorboard',\n",
    "      'source': 'gs://ml-pipeline-dataset/tensorboard-train',\n",
    "    }]\n",
    "  }\n",
    "\n",
    "  # Export two metrics\n",
    "  metrics = {\n",
    "    'metrics': [\n",
    "      {\n",
    "        'name': 'sum',\n",
    "        'numberValue':  float(sum_value),\n",
    "      },{\n",
    "        'name': 'product',\n",
    "        'numberValue':  float(product_value),\n",
    "      }\n",
    "    ]  \n",
    "  }\n",
    "\n",
    "  from collections import namedtuple\n",
    "  example_output = namedtuple(\n",
    "      'ExampleOutputs',\n",
    "      ['sum', 'product', 'mlpipeline_ui_metadata', 'mlpipeline_metrics'])\n",
    "  return example_output(sum_value, product_value, metadata, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  (Optional.) If your function has complex dependencies, choose or build a container image for your\n",
    "    Python function to run in. [Learn more about selecting or building your component's container\n",
    "    image](#containers).\n",
    "    \n",
    "3.  Call [`kfp.components.create_component_from_func(func)`][create-component-from-func] to convert\n",
    "    your function into a pipeline component.\n",
    "    \n",
    "    *   **func**: The Python function to convert.\n",
    "    *   **base_image**: (Optional.) Specify the Docker container image to run this function in.\n",
    "        [Learn more about selecting or building a container image](#containers).  \n",
    "    *   **output_component_file**: (Optional.) Writes your component definition to a file. You can\n",
    "        use this file to share the component with colleagues or reuse it in different pipelines.\n",
    "    *   **packages_to_install**: (Optional.) A list of versioned Python packages to install before\n",
    "        running your function. \n",
    "    \n",
    "<a name=\"packages\"></a>\n",
    "### Using and installing Python packages\n",
    "\n",
    "When Kubeflow Pipelines runs your pipeline, each component runs within a Docker container image on a\n",
    "Kubernetes Pod. To load the packages that your Python function depends on, one of the following must\n",
    "be true:\n",
    "\n",
    "*   The package must be installed on the container image.\n",
    "*   The package must be defined using the `packages_to_install` parameter of the\n",
    "    [`kfp.components.create_component_from_func(func)`][create-component-from-func] function.\n",
    "*   Your function must install the package. For example, your function can use the\n",
    "    [`subprocess` module][subprocess] to run a command like `pip install` that installs a package.\n",
    "\n",
    "<a name=\"containers\"></a>\n",
    "### Selecting or building a container image\n",
    "\n",
    "Currently, if you do not specify a container image, your Python-function based component uses the\n",
    "[`python:3.7` container image][python37]. If your function has complex dependencies, you may benefit\n",
    "from using a container image that has your dependencies preinstalled, or building a custom container\n",
    "image. Preinstalling your dependencies reduces the amount of time that your component runs in, since\n",
    "your component does not need to download and install packages each time it runs.\n",
    "\n",
    "Many frameworks, such as [TensorFlow][tf-docker] and [PyTorch][pytorch-docker], and cloud service\n",
    "providers offer prebuilt container images that have common dependencies installed.\n",
    "\n",
    "If a prebuilt container is not available, you can build a custom container image with your Python\n",
    "function's dependencies. For more information about building a custom container, read the\n",
    "[Dockerfile reference guide in the Docker documentation][dockerfile].\n",
    "\n",
    "If you build or select a container image, instead of using the default container image, the container\n",
    "image must use Python 3.5 or later.\n",
    "\n",
    "[python37]: https://hub.docker.com/layers/python/library/python/3.7/images/sha256-7eef781ed825f3b95c99f03f4189a8e30e718726e8490651fa1b941c6c815ad1?context=explore\n",
    "[create-component-from-func]: https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.components.html#kfp.components.create_component_from_func\n",
    "[subprocess]: https://docs.python.org/3/library/subprocess.html\n",
    "[tf-docker]: https://www.tensorflow.org/install/docker\n",
    "[pytorch-docker]: https://hub.docker.com/r/pytorch/pytorch/tags\n",
    "[dockerfile]: https://docs.docker.com/engine/reference/builder/\n",
    "\n",
    "## Example Python function-based component\n",
    "\n",
    "This section demonstrates how to build a Python function-based component that uses imports,\n",
    "helper functions, and produces multiple outputs.\n",
    "\n",
    "1.  Define your function. This example function uses the `numpy` package to calcuate the quotient\n",
    "    and remainder for a given dividend and divisor in a helper function. In addition to the quotient\n",
    "    and remainder, the function also returns metadata for visualization and two metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "def my_divmod(dividend: float, divisor: float) -> NamedTuple(\n",
    "    'MyDivmodOutput',\n",
    "    [\n",
    "      ('quotient', float),\n",
    "      ('remainder', float),\n",
    "      ('mlpipeline_ui_metadata', 'UI_metadata'),\n",
    "      ('mlpipeline_metrics', 'Metrics')\n",
    "    ]):\n",
    "    '''Divides two numbers and calculate  the quotient and remainder'''\n",
    "    \n",
    "    # Import the numpy package inside the component function\n",
    "    import numpy as np\n",
    "\n",
    "    # Define a helper function\n",
    "    def divmod_helper(dividend, divisor):\n",
    "        return np.divmod(dividend, divisor)\n",
    "\n",
    "    (quotient, remainder) = divmod_helper(dividend, divisor)\n",
    "\n",
    "    from tensorflow.python.lib.io import file_io\n",
    "    import json\n",
    "    \n",
    "    # Export a sample tensorboard\n",
    "    metadata = {\n",
    "      'outputs' : [{\n",
    "        'type': 'tensorboard',\n",
    "        'source': 'gs://ml-pipeline-dataset/tensorboard-train',\n",
    "      }]\n",
    "    }\n",
    "\n",
    "    # Export two metrics\n",
    "    metrics = {\n",
    "      'metrics': [{\n",
    "          'name': 'quotient',\n",
    "          'numberValue':  float(quotient),\n",
    "        },{\n",
    "          'name': 'remainder',\n",
    "          'numberValue':  float(remainder),\n",
    "        }]}\n",
    "\n",
    "    from collections import namedtuple\n",
    "    divmod_output = namedtuple(\n",
    "        'MyDivmodOutput',\n",
    "        ['quotient', 'remainder', 'mlpipeline_ui_metadata', 'mlpipeline_metrics'])\n",
    "    return divmod_output(quotient, remainder, json.dumps(metadata), json.dumps(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  Test your function by running it directly, or with unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_divmod(100, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.  This should return a result like the following:\n",
    "\n",
    "    ```\n",
    "    MyDivmodOutput(quotient=14, remainder=2, mlpipeline_ui_metadata='{\"outputs\": [{\"type\": \"tensorboard\", \"source\": \"gs://ml-pipeline-dataset/tensorboard-train\"}]}', mlpipeline_metrics='{\"metrics\": [{\"name\": \"quotient\", \"numberValue\": 14.0}, {\"name\": \"remainder\", \"numberValue\": 2.0}]}')\n",
    "    ```\n",
    "\n",
    "4.  Use `kfp.components.create_component_from_func` to return a factory function that you can use to create\n",
    "    [`kfp.dsl.ContainerOp`][container-op] class instances for your pipeline. This example also specifies the base container\n",
    "    image to run this function in.\n",
    "\n",
    "[container-op]: https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.dsl.html#kfp.dsl.ContainerOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divmod_op = comp.func_to_container_op(\n",
    "    my_divmod, base_image='tensorflow/tensorflow:1.11.0-py3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.  Define your pipeline. This example uses the `divmod_op` factory function and the `add_op`\n",
    "    factory function from an earlier example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp.dsl as dsl\n",
    "@dsl.pipeline(\n",
    "   name='Calculation pipeline',\n",
    "   description='An example pipeline that performs arithmetic calculations.'\n",
    ")\n",
    "def calc_pipeline(\n",
    "   a='1',\n",
    "   b='7',\n",
    "   c='17',\n",
    "):\n",
    "    # Passes a pipeline parameter and a constant value as operation arguments.\n",
    "    add_task = add_op(a, 4) # The add_op factory function returns\n",
    "                            # a dsl.ContainerOp class instance. \n",
    "    \n",
    "    # Passes the output of the add_task and a pipeline parameter as operation\n",
    "    # arguments. For an operation with a single return value, the output\n",
    "    # reference are accessed using `task.output` or\n",
    "    # `task.outputs['output_name']`.\n",
    "    divmod_task = divmod_op(add_task.output, b)\n",
    "\n",
    "    # For an operation with multiple return values, output references are\n",
    "    # accessed as `task.outputs['output_name']`.\n",
    "    result_task = add_op(divmod_task.outputs['quotient'], c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.  Create and run your pipeline. [Learn more about creating and running pipelines][build-pipelines].\n",
    "\n",
    "[build-pipelines]: https://www.kubeflow.org/docs/pipelines/sdk/build-component/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify pipeline argument values\n",
    "arguments = {'a': '7', 'b': '8'}\n",
    "\n",
    "# Submit a pipeline run\n",
    "client.create_run_from_pipeline_func(calc_pipeline, arguments=arguments)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

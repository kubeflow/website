---
title: Running Multiple Instances of the Spark Operator
description: |
    Running Multiple Instances of the Spark Operator within the Same K8s Cluster
weight: 70
---

{{% alert title="Important" color="warning" %}}
Spark Operator creates **cluster-scoped resources** such as
`MutatingWebhookConfiguration`, `ValidatingWebhookConfiguration`, and `ClusterRole`.

Because of this, running Spark Operator instances in **different namespaces**
within the same Kubernetes cluster is **not supported** and will result in
resource conflicts.

The recommended approach is to:
- Deploy Spark Operator **once** (or multiple releases) in a **single operator namespace**
- Configure each instance to watch **different Spark job namespaces**
  using `spark.jobNamespaces`
{{% /alert %}}

If you need to run multiple instances of the Spark operator within the same k8s cluster, then you need to ensure that the running instances should not watch the same spark job namespace.
For example, you can deploy two Spark operator instances in the `spark-operator` namespace, one with release name `spark-operator-1` which watches the `spark-1` namespace:

```bash
# Create the spark-1 namespace if it does not exist
kubectl create ns spark-1

# Install the Spark operator with release name spark-operator-1
helm install spark-operator-1 spark-operator/spark-operator \
    --namespace spark-operator \
    --create-namespace \
    --set 'spark.jobNamespaces={spark-1}'
```

And then deploy another one with release name `spark-operator-2` which watches the `spark-2` namespace:

```bash
# Create the spark-2 namespace if it does not exist
kubectl create ns spark-2

# Install the Spark operator with release name spark-operator-2
helm install spark-operator-2 spark-operator/spark-operator \
    --namespace spark-operator \
    --create-namespace \
    --set 'spark.jobNamespaces={spark-2}'
```

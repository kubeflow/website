+++
title = "NVIDIA Triton Inference Server"
description = "Model serving with Triton Inference Server"
weight = 50
+++

Kubeflow currently doesn't have a specific guide for NVIDIA Triton Inference 
Server. See the [NVIDIA 
documentation](https://github.com/NVIDIA/triton-inference-server/tree/master/deploy/single_server)
for instructions on running NVIDIA inference server on Kubernetes.

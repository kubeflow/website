+++
title = "NVIDIA TensorRT Inference Server"
description = "See Kubeflow [v0.6 docs](https://v0-6.kubeflow.org/docs/components/serving/tfbatchpredict/) for model serving with TRT Inference Server"
weight = 50
+++

NVIDIA TensorRT Inference Server is not supported in Kubeflow versions greater 
than v0.6. See the following guides:

* [NVIDIA 
  documentation](https://github.com/NVIDIA/tensorrt-inference-server/tree/master/deploy/single_server) 
  for information on deploying NVIDIA TensorRT Inference Server on Kubernetes.
* [Kubeflow v0.6 
  documentation](https://v0-6.kubeflow.org/docs/components/serving/trtinferenceserver/)
  for earlier Kubeflow support for model serving with NVIDIA TensorRT Inference 
  Server.
